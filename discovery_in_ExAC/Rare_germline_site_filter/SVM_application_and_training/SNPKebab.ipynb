{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNPKebab is an SVM regression model that predicts the expected allele fraction of a mutation at a given site at a genome. The informative features for the model are the gc content of the region, mappability, proximity to baits, overlap with segmental duplications and germline copy number gains, distribution of germline SNP variant allele fractions closest to the site, and the distance to the nearest germline SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import twobitreader\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions used throughout the notebook\n",
    "\n",
    "## these first two functions are only used if the reference context is a feature in the model ##\n",
    "# bmap = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "# def one_hot(b):\n",
    "#     t = [0,0,0,0]\n",
    "#     if b is not \"N\":\n",
    "#         i = bmap[b]\n",
    "#         t[i] = 1\n",
    "        \n",
    "#     return t\n",
    "\n",
    "# def call_stats_encode(read):\n",
    "    \n",
    "#     coded_seq=[]\n",
    "    \n",
    "#     for char in read:\n",
    "#         coded_seq.extend(one_hot(char))\n",
    "        \n",
    "#     return coded_seq\n",
    "\n",
    "    #return torch.FloatTensor([one_hot(c) for c in read]).requires_grad_(True)\n",
    "\n",
    "#translate alphabetical chromosomes to numbers\n",
    "def chrom2int(x):\n",
    "    if x == 'X':\n",
    "        return 23\n",
    "    elif x == 'Y':\n",
    "        return 24\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "#get reference context based on start and end position\n",
    "def get_reference(genome,chrom,start,end):\n",
    "\n",
    "    contig=genome[str(chrom)]\n",
    "    return contig[start:end+1]\n",
    "\n",
    "#extract the reads from a reference genome\n",
    "def find_reads(chrm,pos,rep_len):\n",
    "\n",
    "    # initialize 2bitreader genome\n",
    "    genome = twobitreader.TwoBitFile(\"hg19.2bit\")\n",
    "    chr=[genome[c] for c in map(str,range(1,23))]\n",
    "    chr.append(genome['X'])\n",
    "    chr.append(genome['Y'])\n",
    "\n",
    "    read=get_reference(genome,chrm,pos-(rep_len//2)-1,pos+(rep_len//2)-1)\n",
    "    \n",
    "    return read\n",
    "\n",
    "#get gc content\n",
    "def gc_content(read):\n",
    "    return (read.count('G')+read.count('C'))/len(read)\n",
    "\n",
    "#identify order of magnitude of a value in log10 space\n",
    "def magnitude(x):\n",
    "    try:\n",
    "        return int(math.log10(x))\n",
    "    except ValueError:\n",
    "        return 1\n",
    "\n",
    "#one-hot encode genomic distances based on the magnitude of the distance in log10 space\n",
    "def distance_encode(dist):\n",
    "    dlist=[0,0,0,0,0,0,0,0]    \n",
    "    i=magnitude(dist)\n",
    "    \n",
    "    dlist[i]=1\n",
    "    \n",
    "    return dlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b11195e06818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0merror_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#shuffle training and holdout data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#TRAINING AND K-FOLD VALIDATION SVM BASELINE\n",
    "\n",
    "#training data name\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "\n",
    "#test data name\n",
    "test_filename=\"test_prepared.txt\"\n",
    "\n",
    "# 10 folds\n",
    "k=10\n",
    "\n",
    "#if loss drops below this value, end training\n",
    "error_tol=1e-4\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "\n",
    "#shuffle training and holdout data\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "cs_holdout=cs.sample(frac=0.1,random_state=1)\n",
    "\n",
    "cs_prep=cs.loc[~cs.index.isin(cs_holdout.index),:]\n",
    "cs_prep.reset_index(inplace=True)\n",
    "cs_holdout.reset_index(inplace=True)\n",
    "\n",
    "cs_k_fold=np.array_split(cs_prep,k)\n",
    "cs_valid=pd.DataFrame()\n",
    "\n",
    "performance_k=[]\n",
    "stdev_k=[]\n",
    "baseline_performance=[]\n",
    "for fold in range(k):\n",
    "\n",
    "    criterion = nn.SmoothL1Loss() \n",
    "    plt.gcf().clear()\n",
    "\n",
    "    cs_train=pd.DataFrame()\n",
    "    \n",
    "    #iterate through fold\n",
    "    for number,group in enumerate(cs_k_fold):\n",
    "        if fold==number:\n",
    "            cs_valid=group\n",
    "        else:\n",
    "            cs_train=cs_train.append(group)\n",
    "        \n",
    "    cs_train=cs_train.reset_index(drop=True)\n",
    "    cs_valid=cs_valid.reset_index(drop=True)\n",
    "    #feature preparation for training\n",
    "    X=[]\n",
    "    y=[]\n",
    "    with torch.no_grad():\n",
    "        for idx,row in cs_train.iterrows():\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                            'af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            values_X = torch.FloatTensor(val).numpy()\n",
    "            values_y = torch.FloatTensor(pd.Series(row['tumor_f'],dtype=np.float32).values).numpy()\n",
    "\n",
    "            X.append(values_X)\n",
    "            y.append(values_y)\n",
    "\n",
    "        #training\n",
    "        clf = SVR(gamma='scale', C=1.0, epsilon=0.01)\n",
    "        clf.fit(X, y)\n",
    "        print(clf.score(X,y))\n",
    "\n",
    "        baseline_loss=[]\n",
    "        base_loss=0\n",
    "        for idx,row in cs_valid.iterrows():\n",
    "\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                            'af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            val = torch.FloatTensor(val).numpy()\n",
    "            base_X = clf.predict(val.reshape(1,-1))        \n",
    "\n",
    "            base_loss+=criterion(torch.from_numpy(base_X),torch.FloatTensor(\n",
    "                        pd.Series(cs_valid.loc[idx,'tumor_f'],dtype=np.float32).values).double())\n",
    "\n",
    "            #plot correlation between predictions and targets\n",
    "            plt.scatter(base_X,cs_valid.loc[idx,'tumor_f'])\n",
    "            plt.xlabel('predicted_af')\n",
    "            plt.ylabel('target_af')\n",
    "            plt.savefig(\"value_pred_\"+str(fold)+\".png\")\n",
    "\n",
    "            if idx%4==3:            \n",
    "                baseline_loss.append(base_loss.item()/4)\n",
    "                base_loss=0\n",
    "                \n",
    "\n",
    "        #plot loss over iterations\n",
    "        plt.gcf().clear()\n",
    "        baseline_performance.append(np.mean(baseline_loss))\n",
    "        plt.scatter(np.arange(0,len(baseline_loss)),baseline_loss,c='r',\n",
    "                    label='baseline' if i == 0 else \"\")\n",
    "        plt.xlabel('batch')\n",
    "        plt.ylabel('loss') \n",
    "        plt.savefig(\"baseline_loss_\"+str(fold)+\".png\")\n",
    "        \n",
    "        print(baseline_performance)\n",
    "        print(np.mean(baseline_performance))\n",
    "        print(np.max(baseline_loss))\n",
    "        plt.gcf().clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (4,44,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Hugo_Symbol  has_segdup_x  gain_overlap_x   af_next   af_prev  \\\n",
      "0              NaN             0               0  0.428571  0.500000   \n",
      "1              NaN             0               0  0.428571  0.500000   \n",
      "2              NaN             0               0  0.428571  0.500000   \n",
      "3              NaN             0               0  0.428571  0.500000   \n",
      "4              NaN             0               0  0.428571  0.500000   \n",
      "5              NaN             0               0  0.428571  0.500000   \n",
      "6              NaN             0               0  0.428571  0.500000   \n",
      "7              NaN             0               0  0.428571  0.500000   \n",
      "8              NaN             0               0  0.428571  0.500000   \n",
      "9              NaN             0               0  0.048544  0.428571   \n",
      "10             NaN             0               0  0.048544  0.428571   \n",
      "11             NaN             0               0  0.048544  0.428571   \n",
      "12             NaN             0               0  0.555556  0.400000   \n",
      "13             NaN             0               0  0.555556  0.400000   \n",
      "14             NaN             0               0  0.555556  0.400000   \n",
      "15             NaN             0               0  0.555556  0.400000   \n",
      "16             NaN             0               0  0.555556  0.400000   \n",
      "17             NaN             0               0  0.555556  0.400000   \n",
      "18             NaN             0               0  0.152174  0.555556   \n",
      "19             NaN             0               0  0.500000  0.500000   \n",
      "20             NaN             0               0  0.500000  0.500000   \n",
      "21             NaN             0               0  0.250000  0.304348   \n",
      "22             NaN             0               0  0.250000  0.304348   \n",
      "23             NaN             0               0  0.422414  0.508197   \n",
      "24             NaN             0               0  0.422414  0.508197   \n",
      "25             NaN             0               0  0.422414  0.508197   \n",
      "26             NaN             0               0  0.422414  0.508197   \n",
      "27             NaN             0               0  0.300000  0.250000   \n",
      "28             NaN             0               0  0.300000  0.230769   \n",
      "29             NaN             0               0  0.300000  0.230769   \n",
      "...            ...           ...             ...       ...       ...   \n",
      "58879          NaN             0               0  0.555556  0.511278   \n",
      "58880          NaN             0               0  0.555556  0.511278   \n",
      "58881          NaN             0               0  0.555556  0.511278   \n",
      "58882          NaN             0               0  0.529412  0.555556   \n",
      "58883          NaN             0               0  0.529412  0.555556   \n",
      "58884          NaN             0               0  0.465517  0.413793   \n",
      "58885          NaN             0               0  0.373832  0.465517   \n",
      "58886          NaN             0               0  0.373832  0.465517   \n",
      "58887          NaN             0               0  0.373832  0.465517   \n",
      "58888          NaN             0               0  0.373832  0.465517   \n",
      "58889          NaN             0               0  0.373832  0.465517   \n",
      "58890          NaN             0               0  0.373832  0.465517   \n",
      "58891          NaN             0               0  0.373832  0.465517   \n",
      "58892          NaN             0               0  0.357143  0.373832   \n",
      "58893          NaN             0               0  0.357143  0.373832   \n",
      "58894          NaN             0               0  0.357143  0.373832   \n",
      "58895          NaN             0               0  0.357143  0.373832   \n",
      "58896          NaN             0               0  0.357143  0.373832   \n",
      "58897          NaN             0               0  0.357143  0.373832   \n",
      "58898          NaN             0               0  0.357143  0.373832   \n",
      "58899          NaN             0               0  0.357143  0.373832   \n",
      "58900          NaN             0               0  0.357143  0.373832   \n",
      "58901          NaN             0               0  0.357143  0.373832   \n",
      "58902          NaN             0               0  0.357143  0.373832   \n",
      "58903          NaN             0               0  0.357143  0.373832   \n",
      "58904          NaN             0               0  0.214286  0.041667   \n",
      "58905          NaN             0               0  0.214286  0.041667   \n",
      "58906          NaN             0               0  0.214286  0.041667   \n",
      "58907          NaN             0               0  0.214286  0.041667   \n",
      "58908          NaN             0               0  0.500000  0.052632   \n",
      "\n",
      "        score_x  gc_content_x  less_than_0.1  between_0.1_0.2  \\\n",
      "0      1.000000      0.693333            1.0              0.0   \n",
      "1      1.000000      0.573333            1.0              0.0   \n",
      "2      0.500000      0.653333            1.0              0.0   \n",
      "3      1.000000      0.680000            1.0              0.0   \n",
      "4      1.000000      0.666667            1.0              0.0   \n",
      "5      1.000000      0.706667            1.0              0.0   \n",
      "6      1.000000      0.573333            1.0              0.0   \n",
      "7      1.000000      0.653333            1.0              0.0   \n",
      "8      1.000000      0.653333            1.0              0.0   \n",
      "9      1.000000      0.666667            0.0              0.0   \n",
      "10     1.000000      0.560000            0.0              0.0   \n",
      "11     1.000000      0.693333            0.0              0.0   \n",
      "12     1.000000      0.733333            1.0              0.0   \n",
      "13     1.000000      0.693333            1.0              0.0   \n",
      "14     1.000000      0.613333            1.0              0.0   \n",
      "15     1.000000      0.680000            1.0              0.0   \n",
      "16     1.000000      0.546667            1.0              0.0   \n",
      "17     1.000000      0.586667            1.0              0.0   \n",
      "18     1.000000      0.680000            0.0              0.0   \n",
      "19     1.000000      0.653333            0.0              0.5   \n",
      "20     1.000000      0.666667            0.0              0.5   \n",
      "21     1.000000      0.626667            0.0              0.0   \n",
      "22     1.000000      0.640000            0.0              0.0   \n",
      "23     1.000000      0.746667            0.0              0.0   \n",
      "24     1.000000      0.760000            0.0              0.0   \n",
      "25     1.000000      0.693333            0.0              0.0   \n",
      "26     1.000000      0.626667            0.0              0.0   \n",
      "27     1.000000      0.613333            0.0              0.0   \n",
      "28     1.000000      0.680000            0.0              0.0   \n",
      "29     1.000000      0.720000            0.0              0.0   \n",
      "...         ...           ...            ...              ...   \n",
      "58879  0.333333      0.640000            0.0              0.0   \n",
      "58880  0.333333      0.640000            0.0              0.0   \n",
      "58881  0.333333      0.520000            0.0              0.0   \n",
      "58882  0.333333      0.533333            0.0              0.0   \n",
      "58883  1.000000      0.640000            0.0              0.0   \n",
      "58884  1.000000      0.666667            0.0              0.0   \n",
      "58885  1.000000      0.453333            0.0              0.0   \n",
      "58886  1.000000      0.546667            0.0              0.0   \n",
      "58887  1.000000      0.493333            0.0              0.0   \n",
      "58888  1.000000      0.506667            0.0              0.0   \n",
      "58889  1.000000      0.546667            0.0              0.0   \n",
      "58890  0.500000      0.466667            0.0              0.0   \n",
      "58891  0.500000      0.466667            0.0              0.0   \n",
      "58892  1.000000      0.466667            0.0              0.0   \n",
      "58893  1.000000      0.426667            0.0              0.0   \n",
      "58894  1.000000      0.413333            0.0              0.0   \n",
      "58895  1.000000      0.493333            0.0              0.0   \n",
      "58896  1.000000      0.386667            0.0              0.0   \n",
      "58897  1.000000      0.320000            0.0              0.0   \n",
      "58898  1.000000      0.466667            0.0              0.0   \n",
      "58899  1.000000      0.400000            0.0              0.0   \n",
      "58900  1.000000      0.386667            0.0              0.0   \n",
      "58901  1.000000      0.560000            0.0              0.0   \n",
      "58902  0.500000      0.320000            0.0              0.0   \n",
      "58903  1.000000      0.733333            0.0              0.0   \n",
      "58904  1.000000      0.506667            1.0              0.0   \n",
      "58905  1.000000      0.506667            1.0              0.0   \n",
      "58906  1.000000      0.506667            1.0              0.0   \n",
      "58907  0.500000      0.573333            1.0              0.0   \n",
      "58908  1.000000      0.573333            0.0              0.0   \n",
      "\n",
      "       between_0.2_0.3  between_0.3_0.4  between_0.4_0.5  between_0.5_0.6  \\\n",
      "0                  0.0              0.0              0.0              0.0   \n",
      "1                  0.0              0.0              0.0              0.0   \n",
      "2                  0.0              0.0              0.0              0.0   \n",
      "3                  0.0              0.0              0.0              0.0   \n",
      "4                  0.0              0.0              0.0              0.0   \n",
      "5                  0.0              0.0              0.0              0.0   \n",
      "6                  0.0              0.0              0.0              0.0   \n",
      "7                  0.0              0.0              0.0              0.0   \n",
      "8                  0.0              0.0              0.0              0.0   \n",
      "9                  0.0              0.0              1.0              0.0   \n",
      "10                 0.0              0.0              1.0              0.0   \n",
      "11                 0.0              0.0              1.0              0.0   \n",
      "12                 0.0              0.0              0.0              0.0   \n",
      "13                 0.0              0.0              0.0              0.0   \n",
      "14                 0.0              0.0              0.0              0.0   \n",
      "15                 0.0              0.0              0.0              0.0   \n",
      "16                 0.0              0.0              0.0              0.0   \n",
      "17                 0.0              0.0              0.0              0.0   \n",
      "18                 0.0              0.0              1.0              0.0   \n",
      "19                 0.0              0.0              0.5              0.0   \n",
      "20                 0.0              0.0              0.5              0.0   \n",
      "21                 0.0              0.0              0.0              1.0   \n",
      "22                 0.0              0.0              0.0              1.0   \n",
      "23                 1.0              0.0              0.0              0.0   \n",
      "24                 1.0              0.0              0.0              0.0   \n",
      "25                 1.0              0.0              0.0              0.0   \n",
      "26                 1.0              0.0              0.0              0.0   \n",
      "27                 0.0              0.0              1.0              0.0   \n",
      "28                 0.0              1.0              0.0              0.0   \n",
      "29                 0.0              1.0              0.0              0.0   \n",
      "...                ...              ...              ...              ...   \n",
      "58879              0.0              0.0              0.0              1.0   \n",
      "58880              0.0              0.0              0.0              1.0   \n",
      "58881              0.0              0.0              0.0              1.0   \n",
      "58882              0.0              0.0              1.0              0.0   \n",
      "58883              0.0              0.0              1.0              0.0   \n",
      "58884              0.0              0.0              1.0              0.0   \n",
      "58885              0.0              0.5              0.0              0.5   \n",
      "58886              0.0              0.5              0.0              0.5   \n",
      "58887              0.0              0.5              0.0              0.5   \n",
      "58888              0.0              0.5              0.0              0.5   \n",
      "58889              0.0              0.5              0.0              0.5   \n",
      "58890              0.0              0.5              0.0              0.5   \n",
      "58891              0.0              0.5              0.0              0.5   \n",
      "58892              0.0              1.0              0.0              0.0   \n",
      "58893              0.0              1.0              0.0              0.0   \n",
      "58894              0.0              1.0              0.0              0.0   \n",
      "58895              0.0              1.0              0.0              0.0   \n",
      "58896              0.0              1.0              0.0              0.0   \n",
      "58897              0.0              1.0              0.0              0.0   \n",
      "58898              0.0              1.0              0.0              0.0   \n",
      "58899              0.0              1.0              0.0              0.0   \n",
      "58900              0.0              1.0              0.0              0.0   \n",
      "58901              0.0              1.0              0.0              0.0   \n",
      "58902              0.0              1.0              0.0              0.0   \n",
      "58903              0.0              1.0              0.0              0.0   \n",
      "58904              0.0              0.0              0.0              0.0   \n",
      "58905              0.0              0.0              0.0              0.0   \n",
      "58906              0.0              0.0              0.0              0.0   \n",
      "58907              0.0              0.0              0.0              0.0   \n",
      "58908              1.0              0.0              0.0              0.0   \n",
      "\n",
      "            predicted_germ_af  \n",
      "0        [0.0624262448743817]  \n",
      "1       [0.06115304950266032]  \n",
      "2       [0.05488409458770943]  \n",
      "3      [0.062183186968554294]  \n",
      "4       [0.06738064893774873]  \n",
      "5       [0.06269449775556074]  \n",
      "6       [0.06115304950266032]  \n",
      "7      [0.061772942633319505]  \n",
      "8       [0.06695090210380189]  \n",
      "9         [0.474213172563094]  \n",
      "10      [0.47297742517916114]  \n",
      "11       [0.4568809603426077]  \n",
      "12      [0.06605161128861808]  \n",
      "13       [0.0693943642604688]  \n",
      "14       [0.0775544681665071]  \n",
      "15      [0.06820589032009827]  \n",
      "16     [0.057961723887922534]  \n",
      "17     [0.060713933795033925]  \n",
      "18       [0.4488834162043871]  \n",
      "19       [0.3049951263265512]  \n",
      "20       [0.3057983817658804]  \n",
      "21       [0.5186182365873733]  \n",
      "22       [0.5386165999951735]  \n",
      "23        [0.266580093771585]  \n",
      "24      [0.27016147955129954]  \n",
      "25       [0.2754264653068256]  \n",
      "26       [0.2751210527132519]  \n",
      "27       [0.4485767953687539]  \n",
      "28       [0.3493637894051373]  \n",
      "29      [0.35329132015104703]  \n",
      "...                       ...  \n",
      "58879    [0.5328688834150916]  \n",
      "58880    [0.5328688834150916]  \n",
      "58881    [0.5369522984718078]  \n",
      "58882   [0.45133166130607766]  \n",
      "58883    [0.4628463408652969]  \n",
      "58884    [0.4587061511335472]  \n",
      "58885   [0.45155360743915746]  \n",
      "58886   [0.45175990239709324]  \n",
      "58887    [0.4516053136172488]  \n",
      "58888   [0.44471559469823674]  \n",
      "58889   [0.44456957123893653]  \n",
      "58890    [0.4445978857776093]  \n",
      "58891    [0.4445978857776093]  \n",
      "58892     [0.370668013157658]  \n",
      "58893     [0.371828477159342]  \n",
      "58894   [0.37219952741657014]  \n",
      "58895    [0.3703303888109344]  \n",
      "58896    [0.3685481130502346]  \n",
      "58897    [0.3671805780472859]  \n",
      "58898     [0.370668013157658]  \n",
      "58899   [0.37256256384193476]  \n",
      "58900    [0.3729175158959352]  \n",
      "58901   [0.36769509348908763]  \n",
      "58902   [0.37188309359223315]  \n",
      "58903   [0.40364816268145803]  \n",
      "58904  [0.056941538479948484]  \n",
      "58905  [0.056941538479948484]  \n",
      "58906  [0.056941538479948484]  \n",
      "58907   [0.05120627064997768]  \n",
      "58908   [0.26033808523703805]  \n",
      "\n",
      "[58909 rows x 14 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use pre-trained model ##\n",
    "\n",
    "#SVM application to test data\n",
    "\n",
    "test_filename=\"test_prepared.txt\"\n",
    "test=pd.read_csv(test_filename,sep='\\t')\n",
    "\n",
    "plt.gcf().clear()\n",
    "\n",
    "#load model\n",
    "with open(\"call_stat_training/svr_germline.pickle\", 'rb') as pickle_file:\n",
    "    clf=pickle.load(pickle_file)\n",
    "\n",
    "predictions=[]\n",
    "for idx,row in test.iterrows():\n",
    "\n",
    "    #prepare test data for prediction\n",
    "    val=distance_encode(row['distance_prev'])\n",
    "    val.extend(distance_encode(row['distance_next']))\n",
    "    val.extend(distance_encode(row['distance_to_bait_x']))\n",
    "    val.extend(pd.Series(row[['has_segdup_x','gain_overlap_x',\n",
    "                                    'af_next','af_prev','score_x','gc_content_x',\n",
    "                             'less_than_0.1','between_0.1_0.2',\n",
    "                                              'between_0.2_0.3','between_0.3_0.4',\n",
    "                                              'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                           dtype=np.float32).values)\n",
    "\n",
    "    val = torch.FloatTensor(val).numpy()\n",
    "    \n",
    "    #predict\n",
    "    base_X = clf.predict(val.reshape(1,-1))\n",
    "    predictions.append(base_X)\n",
    "\n",
    "test['predicted_germ_af']=predictions\n",
    "\n",
    "test.to_csv(\"test_predicted.txt\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9793637914153991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SVM application to test data where the SVM is being trained in the same step as testing\n",
    "\n",
    "#training data name\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "\n",
    "#test data name\n",
    "test_filename=\"test_prepared.txt\"\n",
    "test=pd.read_csv(test_filename,sep='\\t')\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "\n",
    "#shuffle training data\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "plt.gcf().clear()\n",
    "\n",
    "#training data preparation\n",
    "X=[]\n",
    "y=[]\n",
    "with torch.no_grad():\n",
    "    for idx,row in cs.iterrows():\n",
    "        val=distance_encode(row['distance_prev'])\n",
    "        val.extend(distance_encode(row['distance_next']))\n",
    "        val.extend(distance_encode(row['distance_to_bait']))\n",
    "        val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                        'af_next','af_prev','score','gc_content',\n",
    "                                 'less_than_0.1','between_0.1_0.2',\n",
    "                                                  'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                  'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                               dtype=np.float32).values)\n",
    "\n",
    "        values_X = torch.FloatTensor(val).numpy()\n",
    "        values_y = torch.FloatTensor(pd.Series(row['tumor_f'],dtype=np.float32).values).numpy()\n",
    "\n",
    "        X.append(values_X)\n",
    "        y.append(values_y)\n",
    "\n",
    "    #training \n",
    "    clf = SVR(gamma='scale', C=1.0, epsilon=0.01)\n",
    "    clf.fit(X, y)\n",
    "    #print R-squared value between predictions and features\n",
    "    print(clf.score(X,y))\n",
    "\n",
    "    predictions=[]\n",
    "    for idx,row in test.iterrows():\n",
    "        \n",
    "        val=distance_encode(row['distance_prev'])\n",
    "        val.extend(distance_encode(row['distance_next']))\n",
    "        val.extend(distance_encode(row['distance_to_bait_x']))\n",
    "        val.extend(pd.Series(row[['has_segdup_x','gain_overlap_x',\n",
    "                                        'af_next','af_prev','score_x','gc_content_x',\n",
    "                                 'less_than_0.1','between_0.1_0.2',\n",
    "                                                  'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                  'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                               dtype=np.float32).values)\n",
    "\n",
    "        val = torch.FloatTensor(val).numpy()\n",
    "        base_X = clf.predict(val.reshape(1,-1))\n",
    "        predictions.append(base_X)\n",
    "\n",
    "test['predicted_germ_af']=predictions\n",
    "\n",
    "test.to_csv(\"test_predict.txt\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the code that features a neural net implementation to solve the problem of identifying germline skew. While I do not use them, I have kept them for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    # use prior architectures. \n",
    "    def __init__(self): #self,n_input_features,hidden_size,n_layers\n",
    "        super(NNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(37, 72)\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "        self.fc2 = nn.Linear(72, 72)\n",
    "        self.fc3 = nn.Linear(72,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.fc1(x))) \n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csDataset(Dataset):\n",
    "    \"\"\"call stat dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tsv_file (string): Path to the tsv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cs_frame = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        items=distance_encode(self.cs_frame.loc[idx,'distance_prev'])\n",
    "        items.extend(distance_encode(self.cs_frame.loc[idx,'distance_next']))\n",
    "        items.extend(distance_encode(self.cs_frame.loc[idx,'distance_to_bait']))\n",
    "        items.extend(pd.Series(self.cs_frame.loc[idx, ['has_segdup','gain_overlap',\n",
    "                                        'loss_overlap','af_next','af_prev','score','gc_content',\n",
    "                                                      'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                               dtype=np.float32).values)\n",
    "        \n",
    "        features = torch.FloatTensor(items)        \n",
    "        target = torch.FloatTensor(pd.Series(self.cs_frame.loc[idx,'tumor_f'],dtype=np.float32).values)\n",
    "\n",
    "        sample = {'target':target,\n",
    "                  'features': features}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962360394613674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.05253944545984268]\n",
      "[0, 1, 0.07952087372541428]\n",
      "[0, 2, 0.03024531714618206]\n",
      "[0, 3, 0.02602461725473404]\n",
      "[0, 4, 0.07119030505418777]\n",
      "[0, 5, 0.01598242111504078]\n",
      "[0, 6, 0.027178972959518433]\n",
      "[0, 7, 0.012178056873381138]\n",
      "[0, 8, 0.026766687631607056]\n",
      "[0, 9, 0.03332822397351265]\n",
      "[0, 10, 0.05435416102409363]\n",
      "[0, 11, 0.04255320131778717]\n",
      "[0, 12, 0.03861096501350403]\n",
      "[0, 13, 0.024936726316809654]\n",
      "[0, 14, 0.03151020407676697]\n",
      "[0, 15, 0.02520853839814663]\n",
      "[0, 16, 0.05971593037247658]\n",
      "[0, 17, 0.029427893459796906]\n",
      "[1, 0, 0.008918842300772667]\n",
      "[1, 1, 0.06055452302098274]\n",
      "[1, 2, 0.01734192855656147]\n",
      "[1, 3, 0.007535894401371479]\n",
      "[1, 4, 0.05141014978289604]\n",
      "[1, 5, 0.013816886581480503]\n",
      "[1, 6, 0.05092138051986694]\n",
      "[1, 7, 0.0858013704419136]\n",
      "[1, 8, 0.028165442869067192]\n",
      "[1, 9, 0.033078551292419434]\n",
      "[1, 10, 0.03595985099673271]\n",
      "[1, 11, 0.03890211880207062]\n",
      "[1, 12, 0.02136315032839775]\n",
      "[1, 13, 0.06012430787086487]\n",
      "[1, 14, 0.015540623106062412]\n",
      "[1, 15, 0.06400749832391739]\n",
      "[1, 16, 0.01230397168546915]\n",
      "[1, 17, 0.030837342143058777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03028625374039014\n",
      "model\n",
      "[0.03028625374039014]\n",
      "baseline\n",
      "[0.0008803070012053868]\n",
      "0.03028625374039014\n",
      "0.99589670313492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.03977815806865692]\n",
      "[0, 1, 0.04040730372071266]\n",
      "[0, 2, 0.016029877588152885]\n",
      "[0, 3, 0.027393503114581108]\n",
      "[0, 4, 0.03362492471933365]\n",
      "[0, 5, 0.0406283400952816]\n",
      "[0, 6, 0.043320052325725555]\n",
      "[0, 7, 0.017339685931801796]\n",
      "[0, 8, 0.02543572150170803]\n",
      "[0, 9, 0.042185865342617035]\n",
      "[0, 10, 0.029421141371130943]\n",
      "[0, 11, 0.026517342776060104]\n",
      "[0, 12, 0.010474911890923977]\n",
      "[0, 13, 0.02550555020570755]\n",
      "[0, 14, 0.05504125356674194]\n",
      "[0, 15, 0.0552484430372715]\n",
      "[0, 16, 0.030462196096777916]\n",
      "[0, 17, 0.050294727087020874]\n",
      "[0, 18, 0.001665025483816862]\n",
      "[1, 0, 0.012930410914123058]\n",
      "[1, 1, 0.021449191495776176]\n",
      "[1, 2, 0.03353285789489746]\n",
      "[1, 3, 0.031470149755477905]\n",
      "[1, 4, 0.024843156337738037]\n",
      "[1, 5, 0.03452359884977341]\n",
      "[1, 6, 0.016718486323952675]\n",
      "[1, 7, 0.0394064337015152]\n",
      "[1, 8, 0.007802703883498907]\n",
      "[1, 9, 0.05670676752924919]\n",
      "[1, 10, 0.012812605127692223]\n",
      "[1, 11, 0.047570765018463135]\n",
      "[1, 12, 0.06745945662260056]\n",
      "[1, 13, 0.04761631786823273]\n",
      "[1, 14, 0.04470600187778473]\n",
      "[1, 15, 0.014292112551629543]\n",
      "[1, 16, 0.010868232697248459]\n",
      "[1, 17, 0.03248324617743492]\n",
      "[1, 18, 0.003786396700888872]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026461408007889986\n",
      "model\n",
      "[0.03028625374039014, 0.026461408007889986]\n",
      "baseline\n",
      "[0.0008803070012053868, 0.00250992725353454]\n",
      "0.02837383087414006\n",
      "0.9960541217685248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.028559718281030655]\n",
      "[0, 1, 0.015949873253703117]\n",
      "[0, 2, 0.02178327366709709]\n",
      "[0, 3, 0.020597953349351883]\n",
      "[0, 4, 0.03355374187231064]\n",
      "[0, 5, 0.03165321797132492]\n",
      "[0, 6, 0.018059758469462395]\n",
      "[0, 7, 0.04777907952666283]\n",
      "[0, 8, 0.04610659182071686]\n",
      "[0, 9, 0.025009209290146828]\n",
      "[0, 10, 0.027414517477154732]\n",
      "[0, 11, 0.0240896288305521]\n",
      "[0, 12, 0.03495751693844795]\n",
      "[0, 13, 0.025386324152350426]\n",
      "[0, 14, 0.043989915400743484]\n",
      "[0, 15, 0.0033629294484853745]\n",
      "[0, 16, 0.016382282599806786]\n",
      "[0, 17, 0.040536701679229736]\n",
      "[0, 18, 0.004793083760887384]\n",
      "[1, 0, 0.038328059017658234]\n",
      "[1, 1, 0.03962075710296631]\n",
      "[1, 2, 0.008921469561755657]\n",
      "[1, 3, 0.008128125220537186]\n",
      "[1, 4, 0.0031665191054344177]\n",
      "[1, 5, 0.02218521013855934]\n",
      "[1, 6, 0.018104489892721176]\n",
      "[1, 7, 0.06812449544668198]\n",
      "[1, 8, 0.0662289410829544]\n",
      "[1, 9, 0.012108087539672852]\n",
      "[1, 10, 0.028631001710891724]\n",
      "[1, 11, 0.009214811958372593]\n",
      "[1, 12, 0.01419838983565569]\n",
      "[1, 13, 0.008809848688542843]\n",
      "[1, 14, 0.022766850888729095]\n",
      "[1, 15, 0.024461152032017708]\n",
      "[1, 16, 0.018749428912997246]\n",
      "[1, 17, 0.041560254991054535]\n",
      "[1, 18, 0.06308496743440628]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03062516078352928\n",
      "model\n",
      "[0.03028625374039014, 0.026461408007889986, 0.03062516078352928]\n",
      "baseline\n",
      "[0.0008803070012053868, 0.00250992725353454, 0.0027250620177773485]\n",
      "0.03028625374039014\n",
      "0.9967675479145257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.05193880945444107]\n",
      "[0, 1, 0.03533356264233589]\n",
      "[0, 2, 0.009687484242022038]\n",
      "[0, 3, 0.010722811333835125]\n",
      "[0, 4, 0.021927963942289352]\n",
      "[0, 5, 0.03182363510131836]\n",
      "[0, 6, 0.012653971090912819]\n",
      "[0, 7, 0.03554422780871391]\n",
      "[0, 8, 0.06426835805177689]\n",
      "[0, 9, 0.030096033588051796]\n",
      "[0, 10, 0.03193238750100136]\n",
      "[0, 11, 0.020360324531793594]\n",
      "[0, 12, 0.027726318687200546]\n",
      "[0, 13, 0.043195635080337524]\n",
      "[0, 14, 0.05658188462257385]\n",
      "[0, 15, 0.05642547830939293]\n",
      "[0, 16, 0.09280258417129517]\n",
      "[0, 17, 0.04018586128950119]\n",
      "[0, 18, 0.008864756673574448]\n",
      "[1, 0, 0.03785121813416481]\n",
      "[1, 1, 0.011147281154990196]\n",
      "[1, 2, 0.013802911154925823]\n",
      "[1, 3, 0.07092316448688507]\n",
      "[1, 4, 0.044216338545084]\n",
      "[1, 5, 0.04640473425388336]\n",
      "[1, 6, 0.029970472678542137]\n",
      "[1, 7, 0.02331663854420185]\n",
      "[1, 8, 0.033808931708335876]\n",
      "[1, 9, 0.05309271439909935]\n",
      "[1, 10, 0.035732876509428024]\n",
      "[1, 11, 0.04773147031664848]\n",
      "[1, 12, 0.057117901742458344]\n",
      "[1, 13, 0.03695055469870567]\n",
      "[1, 14, 0.007464081514626741]\n",
      "[1, 15, 0.026235712692141533]\n",
      "[1, 16, 0.027247818186879158]\n",
      "[1, 17, 0.03351903706789017]\n",
      "[1, 18, 0.003633569460362196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020598918199539185\n",
      "model\n",
      "[0.03028625374039014, 0.026461408007889986, 0.03062516078352928, 0.020598918199539185]\n",
      "baseline\n",
      "[0.0008803070012053868, 0.00250992725353454, 0.0027250620177773485, 0.0012029617530135194]\n",
      "0.02837383087414006\n",
      "0.9962631317525249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.05497271195054054]\n",
      "[0, 1, 0.07816746830940247]\n",
      "[0, 2, 0.04753706231713295]\n",
      "[0, 3, 0.013662085868418217]\n",
      "[0, 4, 0.0474412627518177]\n",
      "[0, 5, 0.025503478944301605]\n",
      "[0, 6, 0.03425736352801323]\n",
      "[0, 7, 0.04814708232879639]\n",
      "[0, 8, 0.03746848553419113]\n",
      "[0, 9, 0.05184134468436241]\n",
      "[0, 10, 0.027785221114754677]\n",
      "[0, 11, 0.02330332249403]\n",
      "[0, 12, 0.03590086102485657]\n",
      "[0, 13, 0.06066909804940224]\n",
      "[0, 14, 0.007346747908741236]\n",
      "[0, 15, 0.02769111655652523]\n",
      "[0, 16, 0.03829755261540413]\n",
      "[0, 17, 0.005502763204276562]\n",
      "[0, 18, 0.10333605855703354]\n",
      "[1, 0, 0.00943271815776825]\n",
      "[1, 1, 0.04551075026392937]\n",
      "[1, 2, 0.0010213650530204177]\n",
      "[1, 3, 0.019132860004901886]\n",
      "[1, 4, 0.036070141941308975]\n",
      "[1, 5, 0.012407129630446434]\n",
      "[1, 6, 0.041816312819719315]\n",
      "[1, 7, 0.07228979468345642]\n",
      "[1, 8, 0.06179553270339966]\n",
      "[1, 9, 0.014055403880774975]\n",
      "[1, 10, 0.027023036032915115]\n",
      "[1, 11, 0.05065028369426727]\n",
      "[1, 12, 0.046139344573020935]\n",
      "[1, 13, 0.04110933840274811]\n",
      "[1, 14, 0.006601603701710701]\n",
      "[1, 15, 0.0601121261715889]\n",
      "[1, 16, 0.04363951459527016]\n",
      "[1, 17, 0.04038652405142784]\n",
      "[1, 18, 0.04557201266288757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024733711499720812\n",
      "model\n",
      "[0.03028625374039014, 0.026461408007889986, 0.03062516078352928, 0.020598918199539185, 0.024733711499720812]\n",
      "baseline\n",
      "[0.0008803070012053868, 0.00250992725353454, 0.0027250620177773485, 0.0012029617530135194, 0.0013490988209214107]\n",
      "0.026461408007889986\n",
      "0.9964526999258647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.045218080282211304]\n",
      "[0, 1, 0.023642882704734802]\n",
      "[0, 2, 0.04322242736816406]\n",
      "[0, 3, 0.05261434614658356]\n",
      "[0, 4, 0.0261392779648304]\n",
      "[0, 5, 0.022989638149738312]\n",
      "[0, 6, 0.013367699459195137]\n",
      "[0, 7, 0.06408318132162094]\n",
      "[0, 8, 0.06038254126906395]\n",
      "[0, 9, 0.027998516336083412]\n",
      "[0, 10, 0.01943640597164631]\n",
      "[0, 11, 0.018863243982195854]\n",
      "[0, 12, 0.046042490750551224]\n",
      "[0, 13, 0.04326329752802849]\n",
      "[0, 14, 0.046776700764894485]\n",
      "[0, 15, 0.008807072415947914]\n",
      "[0, 16, 0.017797576263546944]\n",
      "[0, 17, 0.05195532739162445]\n",
      "[0, 18, 0.09830358624458313]\n",
      "[1, 0, 0.037456266582012177]\n",
      "[1, 1, 0.021922342479228973]\n",
      "[1, 2, 0.023579871281981468]\n",
      "[1, 3, 0.006925961002707481]\n",
      "[1, 4, 0.0210141371935606]\n",
      "[1, 5, 0.038441892713308334]\n",
      "[1, 6, 0.04061480611562729]\n",
      "[1, 7, 0.060751184821128845]\n",
      "[1, 8, 0.034500233829021454]\n",
      "[1, 9, 0.02323499694466591]\n",
      "[1, 10, 0.06379034370183945]\n",
      "[1, 11, 0.02752103842794895]\n",
      "[1, 12, 0.04389016330242157]\n",
      "[1, 13, 0.01335960440337658]\n",
      "[1, 14, 0.015139801427721977]\n",
      "[1, 15, 0.03784898295998573]\n",
      "[1, 16, 0.058568909764289856]\n",
      "[1, 17, 0.04513855278491974]\n",
      "[1, 18, 0.0006103353225626051]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type NNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0207356212195009\n",
      "model\n",
      "[0.03028625374039014, 0.026461408007889986, 0.03062516078352928, 0.020598918199539185, 0.024733711499720812, 0.0207356212195009]\n",
      "baseline\n",
      "[0.0008803070012053868, 0.00250992725353454, 0.0027250620177773485, 0.0012029617530135194, 0.0013490988209214107, 0.006335022655037001]\n",
      "0.0255975597538054\n",
      "0.9960662004645322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.026721887290477753]\n",
      "[0, 1, 0.06851954013109207]\n",
      "[0, 2, 0.012402198277413845]\n",
      "[0, 3, 0.03696715459227562]\n",
      "[0, 4, 0.05007806047797203]\n",
      "[0, 5, 0.044440239667892456]\n",
      "[0, 6, 0.007411926053464413]\n",
      "[0, 7, 0.047338735312223434]\n",
      "[0, 8, 0.02940528653562069]\n",
      "[0, 9, 0.026957066729664803]\n",
      "[0, 10, 0.06179336830973625]\n",
      "[0, 11, 0.027833444997668266]\n",
      "[0, 12, 0.0356653556227684]\n",
      "[0, 13, 0.0531834252178669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/mleventh/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-c0a60680dde5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             plt.scatter(i+(120*epoch),loss.item(),\n\u001b[0;32m--> 141\u001b[0;31m                 label='training' if i == 0 else \"\")\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4188\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lines.markersize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4190\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This doesn't have to match x, y in size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4192\u001b[0m         \u001b[0;31m# After this block, c_array will be None unless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6585\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6587\u001b[0;31m         \u001b[0mmarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6588\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6589\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m   7819\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7820\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7821\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order, **options)\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0;31m# Process data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m         _data = np.array(data, dtype=dtype, copy=copy,\n\u001b[0;32m-> 2788\u001b[0;31m                          order=order, subok=True, ndmin=ndmin)\n\u001b[0m\u001b[1;32m   2789\u001b[0m         \u001b[0m_baseclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_baseclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2790\u001b[0m         \u001b[0;31m# Check that we're not erasing the mask.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###k-fold val new features###\n",
    "\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "k=10\n",
    "error_tol=1e-4\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "cs_holdout=cs.sample(frac=0.1,random_state=1)\n",
    "\n",
    "cs_prep=cs.loc[~cs.index.isin(cs_holdout.index),:]\n",
    "cs_prep.reset_index(inplace=True)\n",
    "cs_holdout.reset_index(inplace=True)\n",
    "\n",
    "cs_k_fold=np.array_split(cs_prep,k)\n",
    "cs_valid=pd.DataFrame()\n",
    "\n",
    "performance_k=[]\n",
    "stdev_k=[]\n",
    "baseline_performance=[]\n",
    "\n",
    "for fold in range(k):\n",
    "    \n",
    "    net = NNet()\n",
    "\n",
    "    criterion = nn.SmoothL1Loss() \n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001) # maybe replace with Adam\n",
    "    cs_train=pd.DataFrame()\n",
    "\n",
    "    \n",
    "    for number,group in enumerate(cs_k_fold):\n",
    "        if fold==number:\n",
    "            cs_valid=group\n",
    "        else:\n",
    "            cs_train=cs_train.append(group)\n",
    "        \n",
    "    cs_train=cs_train.reset_index(drop=True)\n",
    "    cs_valid=cs_valid.reset_index(drop=True)\n",
    "    transformed_dataset = csDataset(df=cs_train)\n",
    "\n",
    "    cs = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "    \n",
    "    #baseline_testing\n",
    "    X=[]\n",
    "    y=[]\n",
    "    with torch.no_grad():\n",
    "        for idx,row in cs_train.iterrows():\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                            'loss_overlap','af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            values_X = torch.FloatTensor(val).numpy()\n",
    "            values_y = torch.FloatTensor(pd.Series(row['tumor_f'],dtype=np.float32).values).numpy()\n",
    "\n",
    "            X.append(values_X)\n",
    "            y.append(values_y)\n",
    "\n",
    "        clf = SVR(gamma='scale', C=1.0, epsilon=0.01)\n",
    "        clf.fit(X, y)\n",
    "        print(clf.score(X,y))\n",
    "\n",
    "        baseline_loss=[]\n",
    "        base_loss=0\n",
    "        for idx,row in cs_valid.iterrows():\n",
    "\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                            'loss_overlap','af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            val = torch.FloatTensor(val).numpy()\n",
    "            base_X = clf.predict(val.reshape(1,-1))        \n",
    "\n",
    "            base_loss+=criterion(torch.from_numpy(base_X),torch.FloatTensor(\n",
    "                        pd.Series(cs_valid.loc[idx,'tumor_f'],dtype=np.float32).values).double())\n",
    "\n",
    "            if idx%4==3:            \n",
    "                baseline_loss.append(base_loss.item()/4)\n",
    "                base_loss=0\n",
    "\n",
    "        baseline_performance.append(np.mean(baseline_loss))\n",
    "        plt.scatter(np.arange(0,len(baseline_loss)),baseline_loss,c='r',\n",
    "                    label='baseline' if i == 0 else \"\")\n",
    "        plt.xlabel('batch')\n",
    "        plt.ylabel('loss') \n",
    "        plt.savefig(\"baseline_loss_\"+str(fold)+\".png\")\n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "\n",
    "        for i, data in enumerate(cs):\n",
    "            targets, inputs = data['target'],data['features']\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs,targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            print([epoch,i,loss.item()])\n",
    "            \n",
    "            plt.scatter(i+(120*epoch),loss.item(),\n",
    "                label='training' if i == 0 else \"\")\n",
    "            plt.xlabel('batch')\n",
    "            plt.ylabel('loss')\n",
    "        plt.savefig(\"loss_\"+str(fold)+\".png\")\n",
    "        \n",
    "    torch.save(net, \"fold_dev\")\n",
    "            \n",
    "    #eval_df=pd.DataFrame(columns=[\"pred\",\"target\"])        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        transformed_dataset = csDataset(df=cs_valid)\n",
    "\n",
    "        val = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "        net.eval()\n",
    "        shifts=[]\n",
    "        baseline_shifts=[]\n",
    "        plt.gcf().clear()\n",
    "        for i, data in enumerate(val,0):\n",
    "            \n",
    "            targets,inputs=data['target'],data['features']\n",
    "            \n",
    "            outputs=net(inputs)\n",
    "\n",
    "            loss = criterion(outputs,targets)\n",
    "\n",
    "            shifts.append(loss.item())\n",
    "            \n",
    "#             print([outputs,targets])\n",
    "#             plt.scatter(outputs,targets)\n",
    "#             plt.xlabel('predicted_af')\n",
    "#             plt.ylabel('target_af')\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        plt.scatter(np.arange(0,len(shifts)),shifts,c='b',\n",
    "                    label='validation' if i == 0 else \"\")\n",
    "        plt.xlabel('batch')\n",
    "        plt.ylabel('loss') \n",
    "        plt.savefig(\"loss_\"+str(fold)+\".png\")\n",
    "        plt.gcf().clear()\n",
    "\n",
    "        performance=np.mean(shifts)\n",
    "        print(np.mean(shifts))\n",
    "\n",
    "        performance_k.append(performance)\n",
    "\n",
    "        print('model')\n",
    "        print(performance_k)\n",
    "        print('baseline')\n",
    "        print(baseline_performance)\n",
    "        print(np.median(performance_k)\n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    transformed_dataset = csDataset(df=cs_holdout)\n",
    "\n",
    "    val = DataLoader(transformed_dataset, batch_size=4,\n",
    "                    shuffle=True, num_workers=4)\n",
    "    shifts=[]\n",
    "    plt.gcf().clear()\n",
    "    for i, data in enumerate(val,0):\n",
    "\n",
    "        targets,inputs=data['target'],data['features']\n",
    "\n",
    "        outputs=net(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "\n",
    "        shifts.append(loss.item())\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    plt.scatter(np.arange(0,len(shifts)),shifts,c='b',\n",
    "                label='validation' if i == 0 else \"\")\n",
    "    plt.xlabel('batch')\n",
    "    plt.ylabel('loss') \n",
    "    plt.savefig(\"loss_holdout_\"+str(fold)+\".png\")\n",
    "    plt.gcf().clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recapitulate runs from a specific fold\n",
    "net=torch.load(\"fold_dev\")\n",
    "\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "test_filename=\"test_prepared.txt\"\n",
    "k=10\n",
    "error_tol=1e-4\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "#cs=cs.dropna(subset=[\"context\"])\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "cs_holdout=cs.sample(frac=0.1,random_state=1)\n",
    "\n",
    "cs_prep=cs.loc[~cs.index.isin(cs_holdout.index),:]\n",
    "cs_prep.reset_index(inplace=True)\n",
    "cs_holdout.reset_index(inplace=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    transformed_dataset = csDataset(df=cs_holdout)\n",
    "\n",
    "    val = DataLoader(transformed_dataset, batch_size=4,\n",
    "                    shuffle=True, num_workers=4)\n",
    "    shifts=[]\n",
    "    plt.gcf().clear()\n",
    "    for i, data in enumerate(val,0):\n",
    "\n",
    "        targets,inputs=data['target'],data['features']\n",
    "\n",
    "        outputs=net(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "\n",
    "        shifts.append(loss.item())\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    plt.scatter(np.arange(0,len(shifts)),shifts,c='b',\n",
    "                label='validation' if i == 0 else \"\")\n",
    "    plt.xlabel('batch')\n",
    "    plt.ylabel('loss') \n",
    "    plt.savefig(\"loss_holdout_\"+str(fold)+\".png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything past this point are not things I use, but were previous versions that are useful for posterity and nothing else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171395887703373\n",
      "[0.0035008269141375134]\n",
      "0.0035008269141375134\n",
      "0.013061327481129797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148430459310007\n",
      "[0.0035008269141375134, 0.003335426583574657]\n",
      "0.0034181267488560853\n",
      "0.012965677854359424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7143762413214527\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517]\n",
      "0.0033776255148175623\n",
      "0.0165116954941861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7162969528696038\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838]\n",
      "0.003353828986834631\n",
      "0.015038823403115471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7178233685725579\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679]\n",
      "0.003386755185759441\n",
      "0.015248833261790912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7183749543070199\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679, 0.0033699603689244543]\n",
      "0.0033839560496202767\n",
      "0.021485050774715454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7153302639009829\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679, 0.0033699603689244543, 0.0034478814323836804]\n",
      "0.0033930882471579055\n",
      "0.01893579086942874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142792790851415\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679, 0.0033699603689244543, 0.0034478814323836804, 0.0032535146738398085]\n",
      "0.0033756415504931437\n",
      "0.015328138738527064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7163614012887515\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679, 0.0033699603689244543, 0.0034478814323836804, 0.0032535146738398085, 0.003300996579600471]\n",
      "0.0033673476648384023\n",
      "0.020250092955516497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7170729336911758\n",
      "[0.0035008269141375134, 0.003335426583574657, 0.003296623046740517, 0.003282439402885838, 0.003518459981458679, 0.0033699603689244543, 0.0034478814323836804, 0.0032535146738398085, 0.003300996579600471, 0.0033862561569590393]\n",
      "0.0033692385140504664\n",
      "0.01666654453388745\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Random forest baseline test\n",
    "\n",
    "\n",
    "#baseline only\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "test_filename=\"test_prepared.txt\"\n",
    "k=10\n",
    "error_tol=1e-4\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "#cs=cs.dropna(subset=[\"context\"])\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "cs_holdout=cs.sample(frac=0.1,random_state=1)\n",
    "\n",
    "cs_prep=cs.loc[~cs.index.isin(cs_holdout.index),:]\n",
    "cs_prep.reset_index(inplace=True)\n",
    "cs_holdout.reset_index(inplace=True)\n",
    "\n",
    "cs_k_fold=np.array_split(cs_prep,k)\n",
    "cs_valid=pd.DataFrame()\n",
    "\n",
    "performance_k=[]\n",
    "stdev_k=[]\n",
    "baseline_performance=[]\n",
    "\n",
    "#baseline=LinearRegressionModel(31,1)\n",
    "for fold in range(k):\n",
    "    \n",
    "    net = NNet()\n",
    "\n",
    "    criterion = nn.SmoothL1Loss() \n",
    "    # probably choose something I would recommend like Binomial or Beta log like\n",
    "    # can think about KL divergence between observed distribution and predicted i.e. predict parameters of the distribution\n",
    "    # would need coverage to be an input.\n",
    "    # probably simplest is just L1 loss to start\n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001) # maybe replace with Adam\n",
    "    cs_train=pd.DataFrame()\n",
    "    \n",
    "#     lambda1 = lambda epoch: 0.95 ** (epoch // 30) \n",
    "#     scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "    \n",
    "    # use Pytorch dataset and dataloader \n",
    "    # construct a sample by features matrix and then feed that to a data loader\n",
    "    \n",
    "    for number,group in enumerate(cs_k_fold):\n",
    "        if fold==number:\n",
    "            cs_valid=group\n",
    "        else:\n",
    "            cs_train=cs_train.append(group)\n",
    "        \n",
    "    cs_train=cs_train.reset_index(drop=True)\n",
    "    cs_valid=cs_valid.reset_index(drop=True)\n",
    "    #baseline_testing\n",
    "    X=[]\n",
    "    y=[]\n",
    "    with torch.no_grad():\n",
    "        for idx,row in cs_train.iterrows():\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['hwe_fail','has_segdup','gain_overlap',\n",
    "                                            'loss_overlap','af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            values_X = torch.FloatTensor(val).numpy()\n",
    "            values_y = torch.FloatTensor(pd.Series(row['tumor_f'],dtype=np.float32).values).numpy()\n",
    "\n",
    "            X.append(values_X)\n",
    "            y.append(values_y)\n",
    "\n",
    "        clf = RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                           n_estimators=100)\n",
    "        clf.fit(X, y)\n",
    "        print(clf.score(X,y))\n",
    "\n",
    "        baseline_loss=[]\n",
    "        base_loss=0\n",
    "        for idx,row in cs_valid.iterrows():\n",
    "\n",
    "            val=distance_encode(row['distance_prev'])\n",
    "            val.extend(distance_encode(row['distance_next']))\n",
    "            val.extend(distance_encode(row['distance_to_bait']))\n",
    "            val.extend(pd.Series(row[['hwe_fail','has_segdup','gain_overlap',\n",
    "                                            'loss_overlap','af_next','af_prev','score','gc_content',\n",
    "                                     'less_than_0.1','between_0.1_0.2',\n",
    "                                                      'between_0.2_0.3','between_0.3_0.4',\n",
    "                                                      'between_0.4_0.5','between_0.5_0.6']],\n",
    "                                                   dtype=np.float32).values)\n",
    "\n",
    "            val = torch.FloatTensor(val).numpy()\n",
    "            #valid_X.append(val)\n",
    "            base_X = clf.predict(val.reshape(1,-1))\n",
    "            weights = clf.decision_path(val.reshape(1,-1))\n",
    "\n",
    "            base_loss+=criterion(torch.from_numpy(base_X),torch.FloatTensor(\n",
    "                        pd.Series(cs_valid.loc[idx,'tumor_f'],dtype=np.float32).values).double())\n",
    "\n",
    "            if idx%4==3:            \n",
    "                baseline_loss.append(base_loss.item()/4)\n",
    "                base_loss=0\n",
    "\n",
    "        baseline_performance.append(np.mean(baseline_loss))\n",
    "        plt.scatter(np.arange(0,len(baseline_loss)),baseline_loss,c='r',\n",
    "                    label='baseline')\n",
    "        plt.xlabel('batch')\n",
    "        plt.ylabel('loss') \n",
    "        plt.savefig(\"call_stat_training/validation_plots/rf_baseline_loss_\"+str(fold)+\".png\")\n",
    "        \n",
    "        print(baseline_performance)\n",
    "        print(np.mean(baseline_performance))\n",
    "        print(np.max(baseline_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=1, padding=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=3)\n",
    "        self.fc1 = nn.Linear(22*64, 1000)\n",
    "        self.dropout = nn.Dropout(0.1) \n",
    "        self.fc2 = nn.Linear(1000, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        #x.requires_grad_(True)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "def rmse(predictions,target_data):\n",
    "    return np.sqrt(((predictions - target_data) ** 2).mean())\n",
    "\n",
    "bmap = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "def one_hot(b):\n",
    "    t = [0,0,0,0]\n",
    "    if b is not \"N\":\n",
    "        i = bmap[b]\n",
    "        t[i] = 1\n",
    "        \n",
    "    return t\n",
    "\n",
    "def one_hot_binary(val):\n",
    "    tensor = [[0,0,0,0]]\n",
    "    \n",
    "    if val==1:\n",
    "        tensor[0][1]=1\n",
    "    else:\n",
    "        tensor[0][0]=1\n",
    "        \n",
    "    return torch.FloatTensor([tensor]).requires_grad_(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csDataset(Dataset):\n",
    "    \"\"\"call stat dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tsv_file (string): Path to the tsv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cs_frame = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        items=distance_encode(self.cs_frame.loc[idx,'distance_prev'])\n",
    "        items.extend(distance_encode(self.cs_frame.loc[idx,'distance_next']))\n",
    "        items.extend(distance_encode(self.cs_frame.loc[idx,'distance_to_bait']))\n",
    "        items.extend(pd.Series(self.cs_frame.loc[idx, ['has_segdup','gain_overlap',\n",
    "                                        'loss_overlap','af_next','af_prev','score','gc_content','t_ref_count']],\n",
    "                                               dtype=np.float32).values)\n",
    "        \n",
    "        features = torch.FloatTensor(items)        \n",
    "        target = torch.FloatTensor(stats.beta.pdf(np.arange(0,1.01,0.01),self.cs_frame.loc['t_alt_count']+1,\n",
    "                                                  self.cs_Frame['t_ref_count']+1))\n",
    "        #target = target.astype('float')\n",
    "        #features = features.astype('float')\n",
    "        sample = {'target':target,\n",
    "                  'features': features}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "# class ToTensor(object):\n",
    "#     \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "#     def __call__(self, sample):\n",
    "#         features = sample['features']\n",
    "#         target = sample['target']\n",
    "#         return {'target': torch.from_numpy(target),'features': torch.from_numpy(features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9068990300540847\n",
      "[tensor([0.0928], dtype=torch.float64), tensor([0.0725], dtype=torch.float64)]\n",
      "[tensor([0.1501], dtype=torch.float64), tensor([0.0541], dtype=torch.float64)]\n",
      "[tensor([0.5006], dtype=torch.float64), tensor([0.2637], dtype=torch.float64)]\n",
      "[tensor([0.2802], dtype=torch.float64), tensor([0.2926], dtype=torch.float64)]\n",
      "[tensor([0.3044], dtype=torch.float64), tensor([0.0597], dtype=torch.float64)]\n",
      "[tensor([0.1435], dtype=torch.float64), tensor([0.0525], dtype=torch.float64)]\n",
      "[tensor([0.3831], dtype=torch.float64), tensor([0.4788], dtype=torch.float64)]\n",
      "[tensor([0.4408], dtype=torch.float64), tensor([0.5155], dtype=torch.float64)]\n",
      "[tensor([0.4265], dtype=torch.float64), tensor([0.5472], dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Traceback (most recent call last):\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1790, in _validate_key\\n    error()\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1785, in error\\n    axis=self.obj._get_axis_name(axis)))\\nKeyError: \\'the label [t_alt_count] is not in the [index]\\'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"<ipython-input-158-c759b021a57b>\", line 27, in __getitem__\\n    target = torch.FloatTensor(stats.beta.pdf(np.arange(0,1.01,0.01),self.cs_frame.loc[\\'t_alt_count\\']+1,\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1478, in __getitem__\\n    return self._getitem_axis(maybe_callable, axis=axis)\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1911, in _getitem_axis\\n    self._validate_key(key, axis)\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1798, in _validate_key\\n    error()\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1785, in error\\n    axis=self.obj._get_axis_name(axis)))\\nKeyError: \\'the label [t_alt_count] is not in the [index]\\'\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-c822600378e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# debug using a dev set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Traceback (most recent call last):\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1790, in _validate_key\\n    error()\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1785, in error\\n    axis=self.obj._get_axis_name(axis)))\\nKeyError: \\'the label [t_alt_count] is not in the [index]\\'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\\n    samples = collate_fn([dataset[i] for i in batch_indices])\\n  File \"<ipython-input-158-c759b021a57b>\", line 27, in __getitem__\\n    target = torch.FloatTensor(stats.beta.pdf(np.arange(0,1.01,0.01),self.cs_frame.loc[\\'t_alt_count\\']+1,\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1478, in __getitem__\\n    return self._getitem_axis(maybe_callable, axis=axis)\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1911, in _getitem_axis\\n    self._validate_key(key, axis)\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1798, in _validate_key\\n    error()\\n  File \"/Users/mleventh/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1785, in error\\n    axis=self.obj._get_axis_name(axis)))\\nKeyError: \\'the label [t_alt_count] is not in the [index]\\'\\n'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###k-fold val new features, attempt to implement KL divergence###\n",
    "\n",
    "input_filename=\"call_stat_training/small_case_shuffled_medians_segdup_CNV_proxy_map_dist_bait_gc.txt\"\n",
    "test_filename=\"test_prepared.txt\"\n",
    "k=10\n",
    "error_tol=1e-4\n",
    "\n",
    "cs=pd.read_csv(input_filename,sep='\\t')\n",
    "cs=cs.sample(frac=1,random_state=1)\n",
    "#cs=cs.dropna(subset=[\"context\"])\n",
    "cs.reset_index(inplace=True)\n",
    "\n",
    "cs_holdout=cs.sample(frac=0.1,random_state=1)\n",
    "\n",
    "cs_prep=cs.loc[~cs.index.isin(cs_holdout.index),:]\n",
    "cs_prep.reset_index(inplace=True)\n",
    "cs_holdout.reset_index(inplace=True)\n",
    "\n",
    "cs_k_fold=np.array_split(cs_prep,k)\n",
    "cs_valid=pd.DataFrame()\n",
    "\n",
    "performance_k=[]\n",
    "stdev_k=[]\n",
    "baseline_performance=[]\n",
    "\n",
    "#baseline=LinearRegressionModel(31,1)\n",
    "for fold in range(k):\n",
    "    \n",
    "    net = NNet()\n",
    "\n",
    "    criterion = nn.KLDivLoss() \n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001) # maybe replace with Adam\n",
    "    cs_train=pd.DataFrame()\n",
    "    \n",
    "#     lambda1 = lambda epoch: 0.95 ** (epoch // 30) \n",
    "#     scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "    \n",
    "    # use Pytorch dataset and dataloader \n",
    "    # construct a sample by features matrix and then feed that to a data loader\n",
    "    \n",
    "    for number,group in enumerate(cs_k_fold):\n",
    "        if fold==number:\n",
    "            cs_valid=group\n",
    "        else:\n",
    "            cs_train=cs_train.append(group)\n",
    "        \n",
    "    cs_train=cs_train.reset_index(drop=True)\n",
    "    cs_valid=cs_valid.reset_index(drop=True)\n",
    "    transformed_dataset = csDataset(df=cs_train)\n",
    "\n",
    "    cs = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "    \n",
    "    #baseline_testing\n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    for idx,row in cs_train.iterrows():\n",
    "        val=distance_encode(row['distance_prev'])\n",
    "        val.extend(distance_encode(row['distance_next']))\n",
    "        val.extend(distance_encode(row['distance_to_bait']))\n",
    "        val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                        'loss_overlap','af_next','af_prev','score','gc_content']],\n",
    "                                               dtype=np.float32).values)\n",
    "        \n",
    "        values_X = torch.FloatTensor(val).numpy()\n",
    "        values_y = torch.FloatTensor(pd.Series(row['tumor_f'],dtype=np.float32).values).numpy()\n",
    "        \n",
    "        X.append(values_X)\n",
    "        y.append(values_y)\n",
    "\n",
    "    clf = SVR(gamma='scale', C=1.0, epsilon=0.01)\n",
    "    clf.fit(X, y)\n",
    "    print(clf.score(X,y))\n",
    "    \n",
    "    baseline_loss=[]\n",
    "    base_loss=0\n",
    "    for idx,row in cs_valid.iterrows():\n",
    "        \n",
    "        val=distance_encode(row['distance_prev'])\n",
    "        val.extend(distance_encode(row['distance_next']))\n",
    "        val.extend(distance_encode(row['distance_to_bait']))\n",
    "        val.extend(pd.Series(row[['has_segdup','gain_overlap',\n",
    "                                        'loss_overlap','af_next','af_prev','score','gc_content']],\n",
    "                                               dtype=np.float32).values)\n",
    "        \n",
    "        val = torch.FloatTensor(val).numpy()\n",
    "        base_X = clf.predict(val.reshape(1,-1))\n",
    "        \n",
    "        print([torch.from_numpy(base_X),torch.FloatTensor(\n",
    "                    pd.Series(cs_valid.loc[idx,'tumor_f'],dtype=np.float32).values).double()])\n",
    "    \n",
    "        base_loss+=criterion(torch.from_numpy(base_X),torch.FloatTensor(\n",
    "                    pd.Series(cs_valid.loc[idx,'tumor_f'],dtype=np.float32).values).double())\n",
    "        \n",
    "        if idx%4==3:            \n",
    "            baseline_loss.append(base_loss.item()/4)\n",
    "            base_loss=0\n",
    "\n",
    "    baseline_performance.append(np.mean(baseline_loss))\n",
    "\n",
    "    plt.scatter(np.arange(0,len(baseline_loss)),baseline_loss,c='r',\n",
    "                label='baseline' if i == 0 else \"\")\n",
    "    plt.xlabel('batch')\n",
    "    plt.ylabel('loss') \n",
    "    plt.savefig(\"call_stat_training/validation_plots/baseline_loss_\"+str(fold)+\".png\")\n",
    "        \n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "\n",
    "        for i, data in enumerate(cs):\n",
    "            targets, inputs = data['target'],data['features']\n",
    "\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(stats.beta.pdf(np.arange(0,1.01,0.01),outputs+1,inputs.t_ref_count),targets)\n",
    "            # loss = criterion(outputs,label)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            #print([outputs,loss,cs_train.loc[idx,'tumor_f']])\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            #print([epoch,i,loss.item(),outputs])\n",
    "            print([epoch,i,loss.item()])\n",
    "            \n",
    "            plt.scatter(i+(120*epoch),loss.item(),\n",
    "                label='training' if i == 0 else \"\")\n",
    "            plt.xlabel('batch')\n",
    "            plt.ylabel('loss')\n",
    "        #plt.savefig(\"call_stat_training/training_plots/loss_\"+str(fold)+\".png\")\n",
    "            \n",
    "    #eval_df=pd.DataFrame(columns=[\"pred\",\"target\"])        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        transformed_dataset = csDataset(df=cs_valid)\n",
    "\n",
    "        val = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)\n",
    "        net.eval()\n",
    "        shifts=[]\n",
    "        baseline_shifts=[]\n",
    "        plt.gcf().clear()\n",
    "        for i, data in enumerate(val,0):\n",
    "            \n",
    "            targets,inputs=data['target'],data['features']\n",
    "            \n",
    "            outputs=net(inputs)\n",
    "\n",
    "            loss = criterion(outputs,targets)\n",
    "\n",
    "            shifts.append(loss.item())\n",
    "            \n",
    "#             plt.scatter(outputs,targets)\n",
    "#             plt.xlabel('predicted_af')\n",
    "#             plt.ylabel('target_af')\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        plt.scatter(np.arange(0,len(shifts)),shifts,c='b',\n",
    "                    label='validation' if i == 0 else \"\")\n",
    "        plt.xlabel('batch')\n",
    "        plt.ylabel('loss') \n",
    "        plt.savefig(\"loss_\"+str(fold)+\".png\")\n",
    "        plt.gcf().clear()\n",
    "\n",
    "\n",
    "\n",
    "        performance=np.mean(shifts)\n",
    "        print(np.mean(shifts))\n",
    "\n",
    "        performance_k.append(performance)\n",
    "\n",
    "        print(performance_k)\n",
    "        print(baseline_performance)\n",
    "\n",
    "        \n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    transformed_dataset = csDataset(df=cs_holdout)\n",
    "\n",
    "    val = DataLoader(transformed_dataset, batch_size=4,\n",
    "                    shuffle=True, num_workers=4)\n",
    "    shifts=[]\n",
    "    plt.gcf().clear()\n",
    "    for i, data in enumerate(val,0):\n",
    "\n",
    "        targets,inputs=data['target'],data['features']\n",
    "\n",
    "        outputs=net(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "\n",
    "        shifts.append(loss.item())\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    plt.scatter(np.arange(0,len(shifts)),shifts,c='b',\n",
    "                label='validation' if i == 0 else \"\")\n",
    "    plt.xlabel('batch')\n",
    "    plt.ylabel('loss') \n",
    "    plt.savefig(\"loss_holdout_\"+str(fold)+\".png\")\n",
    "    plt.gcf().clear()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
